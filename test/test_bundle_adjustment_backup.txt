#include <cmath>
#include <cstdio>
#include <iostream>



// -------------------------------------
// -------------------------------------

#include <stdio.h>
#include <unistd.h>

#include <opencv2/core/core.hpp>

#include "show_res.h"
#include "feature_detector.h"
#include "feature_tracker.h"
#include "triangulation.h"
#include "motion_estimator.h"
#include "optimizer.h"

using namespace std;
using namespace cv;

#define MAX_FRAME 1000//5000
#define MIN_NUM_FEATURES 200
#define CHAR_SIZE 200

//--------------------------------------------------------------------------------------------
//--------------------------------------------------------------------------------------------
int test_ba(char *dataset_dir, char *resFile)
{
    Mat img1_l, img1_r, img2_l, img2_r;
    Mat R_res, t_res;
    
    clock_t begin = clock();
    clock_t end;
    double elapsed_secs;
    double distance = 0;
    
    Mat traj = Mat::zeros(600, 600, CV_8UC3);
    showRes showTraj(traj, resFile);
    
    // =======================================================
    // Preprocessing
    // =======================================================
    char filename1_l[CHAR_SIZE], filename1_r[CHAR_SIZE], filename2_l[CHAR_SIZE], filename2_r[CHAR_SIZE];
    
    sprintf(filename1_l, "%simage_0/%06d.png", dataset_dir, 0);
    sprintf(filename1_r, "%simage_1/%06d.png", dataset_dir, 0 );
    sprintf(filename2_l, "%simage_0/%06d.png", dataset_dir, 1 );
    sprintf(filename2_r, "%simage_1/%06d.png", dataset_dir, 1);
    
   	img1_l = imread( filename1_l, CV_LOAD_IMAGE_GRAYSCALE );
   	img1_r = imread( filename1_r, CV_LOAD_IMAGE_GRAYSCALE );
   	img2_l = imread( filename2_l, CV_LOAD_IMAGE_GRAYSCALE );
   	img2_r = imread( filename2_r, CV_LOAD_IMAGE_GRAYSCALE );
    
    if(! img1_l.data || ! img1_r.data || !img2_l.data || !img2_r.data)
    {
        cout <<" Could not open or find the image" << endl;
        return -1;
    }
    
    Eigen::MatrixXf P1(3, 4), P2(3, 4);
    P1 << 718.8560,        0, 607.1928,         0,
    0, 718.8560, 185.2157,         0,
    0,        0,   1.0000,         0;
    P2 << 718.8560,        0, 607.1928, -386.1448,
    0, 718.8560, 185.2157,         0,
    0,        0,   1.0000,         0;
    
    Mat P = (Mat_<double>(3, 3) <<718.8560, 0, 607.1928, 0, 718.8560, 185.2157, 0, 0, 1);

    
    Mat R = Mat::eye(3, 3, CV_64F);
    Mat t = Mat(3, 1, CV_64F, cvScalar(0.));
    showTraj.writeRes(R, t);
    
    vector<Point2f> keypoints1_l, keypoints1_r, keypoints2_l, keypoints2_r;
    
    int img_row = img1_l.rows, img_col = img1_l.cols;
    
    featureDetector detector(img_row, img_col, 100);
    detector.directDetect(img1_l, keypoints1_l);
   
    featureTracker tracker;
    tracker.featureTrack(img1_l, img1_r, img2_l, keypoints1_l, keypoints1_r, keypoints2_l);

    vector<int> init_index;
	tracker.getInitIndex(init_index);
    
    triangulation tri(P1, P2);
    vector<Point3f> point_cloud;
    tri.pc_triangulate(keypoints1_l, keypoints1_r, point_cloud);
    
    motionEstimator::motionFromStructureAndImage pose_estimator(P);
    pose_estimator.updatePose(point_cloud, keypoints2_l, R, t);
    
    R_res = R.clone();
    t_res = t.clone();
    showTraj.writeRes(R_res, t_res);
    
    Mat rvec = cv::Mat::zeros(3, 1, CV_64F);
    Rodrigues(R, rvec);
    LocalBA local_ba(point_cloud, keypoints2_l, rvec, t_res);
    
    distance  += sqrt( t.at<double>(0) * t.at<double>(0) + t.at<double>(2) * t.at<double>(2) );
    
    Mat previousImg_l = img2_l.clone();
    Mat previousImg_r = img2_r.clone();
    Mat currentImg_l, currentImg_r;
    vector<Point2f> previousKeypoints = keypoints2_l;
    vector<Point2f> previousKeypoints_r;
    vector<Point2f> currentKeypoints;
    
    char filename_l[100], filename_r[100];
    
    // =======================================================
    // Loop
    // =======================================================
   	int iframe;

   	for (iframe=2; iframe<MAX_FRAME; iframe++){
        sprintf(filename_l, "%simage_0/%06d.png", dataset_dir, iframe);
        sprintf(filename_r, "%simage_1/%06d.png", dataset_dir, iframe);
        currentImg_l = imread( filename_l, CV_LOAD_IMAGE_GRAYSCALE);
        currentImg_r = imread( filename_r, CV_LOAD_IMAGE_GRAYSCALE);
        
        if(! currentImg_l.data)
        {
            cout << "\nTotal image pairs: " <<iframe <<endl;
            cout << "Finish image processing!" << endl;
            break;
        }
        
        tracker.featureTrack(previousImg_l, previousImg_r, currentImg_l, previousKeypoints, previousKeypoints_r, currentKeypoints);
        
        vector<int> track_index;
        tracker.getPointIndex(init_index, track_index);

        vector<Point3f> point_cloud;
        tri.pc_triangulate(previousKeypoints, previousKeypoints_r, point_cloud);
        
        pose_estimator.updatePose(point_cloud, currentKeypoints, R, t);
        
        if (abs(t.at<double>(2)) > abs(t.at<double>(1)) && abs(t.at<double>(2)) > abs(t.at<double>(0)) ){
            t_res = t_res + R_res * t;
            R_res = R * R_res;
            distance  += sqrt( t.at<double>(0) * t.at<double>(0) + t.at<double>(2) * t.at<double>(2) );
            
        }
        
        Rodrigues(R_res, rvec);
		local_ba.addObservation(currentKeypoints, track_index, rvec, t_res);
        
        init_index = track_index;


        if ( currentKeypoints.size() < MIN_NUM_FEATURES ){
            break;
            vector<uchar> status;
            detector.directDetect(currentImg_l, currentKeypoints);
        }
        
        imshow("Camera", currentImg_l);
        showTraj.updateTraj(t_res);
        showTraj.writeRes(R_res, t_res);
        
        previousImg_l = currentImg_l.clone();
        previousImg_r = currentImg_r.clone();
        previousKeypoints = currentKeypoints;
    }
    
    local_ba.finishAddObservation();
    
    // Use ceres to optimize local poses
    google::InitGoogleLogging("Simple example");
    
    
    const double* observations = local_ba.observations();
    cout <<"Got this bitch observation: " <<observations[0] <<" " <<observations[1] <<endl;
    double *a = local_ba.mutable_camera_for_observation(0);
    double *b = local_ba.mutable_point_for_observation(0);
    for(int i=0; i<6; i++) cout <<a[i] <<" ";
    cout <<endl;
    for (int i=0; i<3; i++) cout<<b[i] <<" ";
    cout <<endl;
    
    double x, y;
    Reprojection(a, b, x, y);
    
    cout <<"Why life if sooooo jerk! " <<local_ba.camera_index(0) << "   " <<local_ba.camera_index(1) <<endl;
    cout <<local_ba.camera_index(551) <<endl;
    cout <<"Reproject point:" <<x <<" " <<y <<endl;
    
    cout <<"Camera number: " <<local_ba.num_cameras() <<endl;
    cout <<"Point number:  " <<local_ba.num_points() <<endl;
    cout <<"Observation number: " <<local_ba.num_observations() <<endl;
    
    double* par = local_ba.parameters();
    for(int i=0; i<6; i++)cout <<par[i] <<" ";
    cout <<" " <<endl;
    
    // Create residuals for each observation in the bundle adjustment problem. The
    // parameters for cameras and points are added automatically.
    ceres::Problem problem;
    
    
    for (int i = 0; i < local_ba.num_observations(); ++i) {
        // Each Residual block takes a point and a camera as input and outputs a 2
        // dimensional residual. Internally, the cost function stores the observed
        // image location and compares the reprojection against the observation.
        ceres::CostFunction* cost_function =
        SnavelyReprojectionError::Create(observations[2 * i + 0],
                                         observations[2 * i + 1]);
        problem.AddResidualBlock(cost_function,
                                 NULL /* squared loss */,
                                 local_ba.mutable_camera_for_observation(i),
                                 local_ba.mutable_point_for_observation(i));
    }
    cout <<"Funny thing" <<endl;
    
    // Make Ceres automatically detect the bundle structure. Note that the
    // standard solver, SPARSE_NORMAL_CHOLESKY, also works fine but it is slower
    // for standard bundle adjustment problems.
    ceres::Solver::Options options;
    options.linear_solver_type = ceres::DENSE_SCHUR;
    options.minimizer_progress_to_stdout = true;
    
    ceres::Solver::Summary summary;
    ceres::Solve(options, &problem, &summary);
    std::cout << summary.FullReport() << "\n";
    
    
    
    waitKey(0);
    return 0;
    
}


int main(int argc, char *argv[])
{
    if ( argc != 2 ){
        cerr << "Usage: ./test_stereo test_sequence_no" << endl;
        return -1;
    }
    
    //char dataset_dir[CHAR_SIZE] = "/Users/Muyuan/Documents/vo/evaluation/kitti/data/sequences/";
    char dataset_dir[CHAR_SIZE] = "../evaluation/kitti/data/sequences/";
    
    char res_dir[CHAR_SIZE]; 
    int seq_no = atoi(argv[1]);
    
    sprintf(dataset_dir, "%s%.02d/", dataset_dir, seq_no);
    sprintf(res_dir, "../evaluation/results/data/%.02d.txt", seq_no);
    
    printf("%s\n", dataset_dir);
    printf("%s", res_dir);
    
    test_ba(dataset_dir, res_dir);
    
    return 0;
}
